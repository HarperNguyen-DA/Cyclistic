---
title: "Cyclistic"
author: "Harper Nguyen"
date: "5/25/2021"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Case Study

Scenario
I am working in the marketing analyst team at Cyclistic, a bike-share company in Chicago. 
The director of marketing believes the company’s future success depends on maximizing the number of annual memberships.
Therefore, our team wants to understand how casual riders and annual members use Cyclistic bikes different.
From these insights, our team will design a new marketing strategy to convert casual riders into annual members.

## Phase 1: Ask

Asking 3 questions:
1. How do annual members and casual riders use Cyclistic bikes different?
2. Why would casual riders buy Cyclistic annual memberships?
3. How can Cyclistic use digital media to influence casual riders to become members?

I has been assigned the first question to answer: How do annual members and casual riders use Cyclistic bikes differently?

In particular, I will analyze some questions below:

1. What is total number of trips for members and casuals, which proportion of total trips they represent?
2. Some statistic metrics about ride length for members and casuals (min, max, mean, median)
3. Where are the most common area casuals start and end trips?
4. Which months, days of week, hours of day member and casual ride most?
5. What types of ride, casual and member use most?

## Phase 2: Prepare
 
Where is my data located? - I use Cyclistic’s historical trip data to identify how different casual and member use bikes. 
It's internal resource, the original , reliable source. 
I will use current trips data in 12 months from May 2020 to Apr 2021 which have all data I need to answer my questions above (start and end station name, start and end datetime, ridable type, member_casual).


First, download 12 ".csv" file. Using excel to filter and sort to check data mising in all columns. 
Found out that start_station_name and end_station_name have some blank cells. As the data is large, I will combine all file into 1 table and clean data in R.

### Import required packages

```{r Import required packages}
library(rmarkdown)
library(tidyverse)
# install.packages("sqldf")
library(sqldf)
library(lubridate)
```
### Import data

```{r Import data}

setwd('/Users/harper/data/Data\ analytics/GOogle\ course/Case\ Study/csv/')
m05_2020 <- read.csv('202005-divvy-tripdata.csv')
m06_2020 <- read.csv('202006-divvy-tripdata.csv')
m07_2020 <- read.csv('202007-divvy-tripdata.csv')
m08_2020 <- read.csv('202008-divvy-tripdata.csv')
m09_2020 <- read.csv('202009-divvy-tripdata.csv')
m10_2020 <- read.csv('202010-divvy-tripdata.csv')
m11_2020 <- read.csv('202011-divvy-tripdata.csv')
m12_2020 <- read.csv('202012-divvy-tripdata.csv')
m01_2021 <- read.csv('202101-divvy-tripdata.csv')
m02_2021 <- read.csv('202102-divvy-tripdata.csv')
m03_2021 <- read.csv('202103-divvy-tripdata.csv')
m04_2021 <- read.csv('202104-divvy-tripdata.csv')
```

### Checking the columns name and type of variables
```{r}
glimpse(m05_2020)
glimpse(m06_2020)
glimpse(m07_2020)
glimpse(m08_2020)
glimpse(m09_2020)
glimpse(m10_2020)
glimpse(m11_2020)
glimpse(m12_2020)
glimpse(m01_2021)
glimpse(m02_2021)
glimpse(m03_2021)
glimpse(m04_2021)
```

Notice that all dataframes with the same column names and orders, so merge them into 01 table (12 months)

### Merge into 01 table
```{r Merge into 01 table for all observations in a year}
all_trips <- rbind(m05_2020, m06_2020, m07_2020, m08_2020, m09_2020, 
                   m10_2020, m11_2020, m12_2020, m01_2021, m02_2021, m03_2021,
                   m04_2021)
```
## Phase 3: Process

### Inspect the data to check type
```{r Inspect the data to check type}
summary(all_trips)
```
### Change type from character to datetime
```{r Change type from character to datetime}
all_trips$started_at <- ymd_hms(all_trips$started_at)
all_trips$ended_at <- ymd_hms(all_trips$ended_at)
glimpse(all_trips)
```

### Add new columns: ride_length, day_of_week, hour to aggregate data
```{r Aggregate data}
all_trips1 <- all_trips %>% mutate(ride_length = difftime(ended_at,
                                        started_at, units = 'mins'))
all_trips1$date <- date(all_trips$started_at)
all_trips1$day_of_week <- weekdays(all_trips$started_at)
all_trips1$hour <- hour(all_trips$started_at)
all_trips1$month <- month(all_trips$started_at)
glimpse(all_trips1)
```

### Check type of ride_length and min, max
```{r}
typeof(all_trips1$ride_length)
all_trips1 %>% summarise(ride_min = min(ride_length), ride_max = max(ride_length))
```
### Remove all missing values & errors
Remove all missing values in start_station_name and end_station_name
Also Remove all error values for ride_length (which =<0 and >=1440 minutes or 24hours)

```{r tidy=TRUE}
all_trips2 <- subset(all_trips1, all_trips1$ride_length > 0
                     & all_trips1$ride_length < 1440
                     & all_trips1$start_station_name!="" 
                     & all_trips1$end_station_name!="")
colnames(all_trips2)
```
### Select only some columns needed to analyze
```{r tidy=TRUE}
all_trips_conclusion <- all_trips2 %>% 
  select(ride_id, rideable_type, started_at, ended_at, member_casual, 
         date, ride_length, day_of_week, month, hour)
```

## Phase 4 & 5: Analyze and Share (Visualization)

### What is total number of trips for members and casuals, which proportion of total trips they represent?

```{r}
all_trips_conclusion %>%
    group_by(member_casual)%>% 
    summarise(num_trips = n()) %>% 
    mutate(proportion = round(num_trips / sum(num_trips)*100,0))
```


### Calculate some statistic metrics for ride_length as min, max, mean, median

```{r}
all_trips_conclusion %>%
    group_by(member_casual) %>% 
    summarise(min_ride_length = min(ride_length), 
              max_ride_length = max(ride_length), 
              median_ride_length = median(ride_length),
              mean_ride_length = mean(ride_length))
```
### Using SQL code to query in R
Top 10 common start and end stations casual took trips by using sqldf function

```{r tidy=TRUE}
casual_geo_start <- sqldf("SELECT member_casual, start_station_name,
count(start_station_name) AS num_trips
                   FROM all_trips2
                   WHERE member_casual = 'casual'
                   GROUP BY start_station_name
                   ORDER BY count(start_station_name) DESC
                   LIMIT 10", method='auto')
casual_geo_start

casual_geo_end <- sqldf("SELECT member_casual, end_station_name,
count(end_station_name) AS num_trips
                   FROM all_trips2
                   WHERE member_casual = 'member'
                   GROUP BY end_station_name
                   ORDER BY count(end_station_name) DESC
                   LIMIT 10", method='auto')
casual_geo_end

```

### Visualization

#### Which days of week, hours of day member and casual ride most?

```{r days of week}
all_trips_conclusion %>%
    group_by(member_casual, day_of_week) %>%
    summarise(num_trips = n(), .groups = 'drop') %>%
    ggplot(aes(x = factor(day_of_week, 
                          weekdays(min(all_trips_conclusion$date) + 3:9)), 
               y = num_trips, fill = member_casual)) + 
    geom_bar(position = "dodge", stat = "identity") +
    labs(title = "Yearly Total Rides Per Day of Week.", x = "Day of Week", 
         y = "Total Rides") +
    scale_y_continuous(labels = function(x) format(x, scientific = FALSE))
```

```{r hour}
all_trips_conclusion %>%
    group_by(member_casual, hour) %>%
    summarise(num_trips = n(), .groups = 'drop') %>%
    ggplot(aes(x = hour, y = num_trips, fill = member_casual, colour= member_casual)) +
    geom_line(size=1) + geom_point(size=3)+
    scale_x_continuous(breaks=c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,
                                14,15,16,17,18,19,20,21,22,23))
```

```{r months}
all_trips_conclusion %>%
    group_by(member_casual, month) %>%
    summarise(num_trips = n(), .groups = 'drop') %>%
    ggplot(aes(x = month, y = num_trips, fill = member_casual, colour= member_casual)) + 
    geom_line(size=1) + geom_point(size=3) +
    scale_x_continuous(breaks=c(0,1,2,3,4,5,6,7,8,9,10,11,12)) +
    scale_y_continuous(labels = function(x) format(x, scientific = FALSE))
```

```{r}
all_trips_conclusion %>%
    group_by(member_casual, rideable_type) %>%
    summarise(num_trips = n(), .groups = 'drop') %>%
    ggplot(aes(x = rideable_type, y = num_trips, fill = member_casual)) + 
    geom_bar(position = "dodge", stat = "identity")+
    scale_y_continuous(labels = function(x) format(x, scientific = FALSE))
```
### Phase 6: Act

Casual trips account for 41% total trip.
If we can convert casual to member, revenue will increase significantly.

Some insights I found out:
What different between members and casuals use bikes?

Ride length: Members most likely use bike for 15 minutes while casuals tend to use for longer time (30 minutes)
When they use most: 
- Month: both members and casuals use most from July to September.
- Day of week: casuals most likely use in the weekend (Friday-Sunday) while members use all days of week, not much different between days of week. Maybe members use for commuting to work whereas casuals only use for hanging out.
- Hour: Peak hours are from 15PM-18PM both members and casuals.
Type of ride: Both use docked bike most compared to the others.

Recommendation:

1. Run special discount for membership in some criteria that casuals most likely use so they will see the benefits if convert to be members and those who are members also enjoying their benefits of membership:
  - docked_bike
  - 15PM-18PM
  - unlimited ride duration.
2. Run the advertising campaign to focus on benifit to use bike_share for commuting to work so casuals use more in weekday instead of weekend only.
  If they ride bikes to work, they tend to use much more and consider to convert to member to have more promotion.
3. Especially should run advertising campaign in peak season (July - September), so there are more chances casuals should register for membership.
4. Launch advertising campaign for membership on the 10 common start and end stations where casual took rides most.

